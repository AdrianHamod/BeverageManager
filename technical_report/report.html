<!doctype html>
<html lang="enlgish">
<head>
    <style type="text/css">
        body {
            width: 7in;
            height: 9.25in;
            margin: 27mm 16mm 27mm 16mm;
        }
    </style>
    <meta charset="utf-8">
    <title>Beverage Manager technical report</title>
</head>

<article>
    <header>
        <h1>Beverage Manager technical report</h1>
        <div role="contentinfo">
            <section typeof="sa:AuthorsList">
                <h2>Contributors</h2>
                <ul>
                    <li typeof="sa:ContributorRole" property="schema:author">
              <span typeof="schema:Person">
                <meta property="schema:givenName" content="Adrian">
                <meta property="schema:familyName" content="Hamod">
                <span property="schema:name">Adrian Hamod</span>
              </span>
                        <ul>
                            <li property="schema:roleContactPoint" typeof="schema:ContactPoint">
                                <a href="mailto:adrianhamod@gmail.com" property="schema:email"> adrianhamod@gmail.com
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li typeof="sa:ContributorRole" property="schema:author">
              <span typeof="schema:Person">
                <meta property="schema:givenName" content="Dorian">
                <meta property="schema:additionalName" content="Gheorghe">
                <meta property="schema:familyName" content="Olărescu">
                <span property="schema:name">Dorian Olărescu</span>
              </span>
                        <ul>
                            <li property="schema:roleContactPoint" typeof="schema:ContactPoint">
                                <a href="mailto:dorian.olarescu@gmail.com" property="schema:email"> dorian.olarescu@gmail.com
                                </a>
                            </li>
                        </ul>
                    </li>
                </ul>
            </section>
            <section>
                <h2>License and copyright</h2>
                <h3>
                    <a href="https://creativecommons.org/licenses/by/4.0/" property="schema:license" typeof="CreativeWork">License</a>
                    </h3>
                        <div property="schema:copyrightYear"></div>
                        <h3>Copyright</h3>
                        <ul>
                            <li property="schema:copyrightYear">2021</li>
                            <li property="schema:copyrightHolder" typeof="schema:Organization">
                                Facultatea de Informatică - Universitatea Alexandru Ioan Cuza
                            </li>
                        </ul>
            </section>
            <section typeof="sa:Abstract">
                <h2>Abstract</h2>
                This report details the technical aspects of building a web application
                around an ontological model describing the most common non-alcoholic beverages.
                The application described is stateful by design allowing users interacting
                with it to express preferences towards beverages. The mentioned preferences are
                modelled as a knowledge graph whereas the beverage resources are modelled
                to include specific metadata (e.g.: category, price, ingredients etc.). In terms of features the application should also support browsing, filtering and even
                suggestions or correlations.
                The report showcases topics such as internal data structures, linked data principles, technologies used, cost of infrastructure, SLAs. For convinience, in the following sections we will reffer to the application as BEM - abvreviation for Beverage Manager, title of the project and application.
            </section>
            <section>
                <h2>1.0 BEM overview</h2>
                <section>
                    <h3>1.1 Service overview</h3>
                    The BEM service handles requests over an http connection. Over this connection authenticated clients can view queried resources rendered in html format. The frontend service handles delivery of static assets (html, css, js) and forwarding the queries to the query backend service. The backend service exposes and API for retrieving json representations of interlinked resources in RDF format. The API can also be made available for programmatic access or unauthenticated access as long as it accesses immutable resources describing non-user data (beverages excepting user preferences). Beverage related resources can be accessed via the /beverage/{resource} path where {resource} is a path parameter indicating the name of the resource. User preferences are available through the /profile/{user} route where {user} is a path parameter indicating the name of the user. The backend service queries the internal RDF storage to retrieve data and It can also be extended to run SPARQL queries on public sets of data such as DBPedia in order to merge additional metadata and link to external sources of data. RDF4J supports queries on remote SPARKQL endpoints such as DBPedia through the SPARKQLRepository API https://rdf4j.org/documentation/programming/setup/#accessing-a-sparql-endpoint
                </section>
                <section>
                    <h3>1.2 Internal data representation</h3>
                    The service internal model representation of data and resources is divided into 2 categories. As mentioned before accessing RDF data stores is done through the RDF4J Repository API. This enables us to work directly with the RDF4J Model API which provides class containers for the abstract RDF concepts. Resources are defined as IRI objects, literals are modeled as Literal objects, Statement objects abstract the concepts of subject, predicate and object through the use of IRIs and lastly blank nodes are represented through BNode object or null values. This model classes are used as entity objects when communicating with a data store such as DBPedia or our own ontology storage.
                    When serving response the http requests the body of the response will contain a JSON-ld representation of the data.
                </section>
                <section>
                    <h3>1.3 Internal storage</h3>
                    For our internal ontology storage, we use a dedicated ElasticSearch instance since the Repository API offers a direct integration with it. Storing the data on a separate instance, as opposed to a in memory storage enables us to future proof for extensions such as database replication if there are concerns regarding availability or durability. One advantage of an in-memory storage is the fast access to data. Even so, the data retrievals from a remote server can be improved through caching solutions such as Redis if there are concerns in this sense.
                </section>
                <section>
                    <h3>1.4 Linked data principles</h3>
                    We can outline several ideas mentioned above that describe the linked data feature of the application. Stored data is available on the web through the use of an HTTP connection. The ontology resources are described through unique URIs. The internal data is modelled in RDF format using the RDF4J API and the output is in JSON-LD representation. Outputted resources include links to other internal resources to which they describe relations. This linking is done through metadata links to those resources. This linking can be further improved through querying/merging external data available in other public stores such as DBPedia
                </section>
            </section>
            <section>
                <h2>2.0 Technologies used</h2>
                <section>
                    <h3 id="designAndArchitecture">2.1 Design and architecture</h3>
                    A general architecture of the application and preliminary design considerations
                    are available in the <a href="https://github.com/AdrianHamod/BeverageManager/tree/main/architecture">project repository</a>. This includes a diagram describing the service oriented architecture, preliminary UML representation of the backend service, OpenAPI specification of the public APIs exposed and descriptions of the application flow, query service and end client use cases.
                </section>
                <section>
                    <section>
                        <h4>2.1.1 Angular</h4>
                        Angular was our choice as the platform for building the user interface of the application. It is a platform and framework for building single-page web applications using modern web platform capabilities delivering high performance, offline and zero-step installation.
                        Single-Page Applications (or SPAs) refer to the application being dynamic, that is, when a user navigates the app, no page reloading is happening, but the data is received and sent back to the server, but the app itself does not load new pages from the server every time there is some action happening.
                    </section>
                    <section>
                        Angular is considered by many a 'default' front-end tool and some of the reasons are because it is very versatile, has the ability of combining business logic and UI elements offering a lot of features that help to scale, optimize and speed up web applications.
                        It includes numerous structural elements like Injectors, Components, Directives, Pipes, Services, etc. that raise the complexity of Angular as a platform, but creates high quality applications as a result.
                        Some other benefits of using Angular are its very detailed documentation, two-way data binding that allows apps to update in real time if the binding source has changed (the backing value), differential loading that allow creating of two kinds of bundles, one for modern browsers that support ES2015+, and another one for older ones that support ES5 making the app more efficient and speedy by loading less code and polyfills.
                        And finally, it was created by Google, so it has its support with small updates every 6 months, gradually improving the framework.
                    </section>
                    <section>
                        For our use-case, Angular helps with providing a solid web application, that can easily support very large amounts of data, while being fast and responsive, with a minimal footprint.
                        Using Angular with Spring was a very easy choice since the two form a powerful combination. One such benefit it has the controls necessary for displaying complex lists of data, with two way binding allowing for the UI to receive data from the API, but also send UI updates to the API, such as when you click to rate, the rate controller is already bound to a value that, when changed, updates it at API level.
                    </section>
                </section>
                <section>
                    <h4>2.1.2 Spring</h4>
                    We have chosen to use Spring to develop a solid backend for our app. It is the most popular application framework for Java. It provides a comprehensive programming and configuration model as well as great support for a SOA architecture with microservices.
                    Spring also offers spring-boot which is an easy solution to make stand-alone, production-grade Spring applications that can just be run with metrics, health checks and externalized configuration with no code generation and no XML configuration requirement.
                    Spring uses servlets behind the scenes, which are based upon a low-level API for handling requests and responses. That means that every part of the web api flow is made much easier, from returning a JSON using @ResponseBody to RESTful URLs, input validation, form data binding to object and much much more.
                    It is also multithreaded, supporting asynchronous request processing where, instead of returning a value, the controller method can return a Callable object and produce the return value from a separate thread, while the main Servlet container thread is released and ready to process other requests. It does so using the TaskExecutor and when the Callable object returns, the request is dispatched back to the Servlet container to resume processing with the value returned by the Callable.
                    In our case, using Spring and Spring-Boot kickstarts our project by having ready-made project templates, easy Angular support, by exposing controllers through API Gateway and rich documentation for AWS integration. It is a strong foundation for any size the app could reach.
                </section>

                <section>
                    <h3>2.2 Cloud services</h3>
                    In order to orchestrate, deploy and ease the resource management several AWS services are used.
                    <section>
                        <h4>2.2.1 API Gateway</h4>
                        API Gateway is a service for managing API routing at service level as opposed to how popular web frameworks manage API routing at application domain level. What this means is requests are handled by central unit which resolves the service appropirate to delegate the request to. This is particularly useful in service oriented architectures where microservices are standalone applications and require an orchestration logic for the application flow to be implemented.
                        API Gateway, being the application entry point, can conveniently handle authorization. We opt for using a 3rd party JWT authorizer which we directly integrate with API Gateway. Thus, once authenticated using the application internal logic, we can delegate authorization to API Gateway and authorize requests based on a speciffic header value.
                        Lastly, we use API Gateway to manage throttling. Managing thortling at service level and delegating it to a trusted 3rd party such as AWS puts aside the operational burden of using intercepetor classes at the framework level with a proprietary implementation which must be maintained and tested.
                    </section>
                    <section>
                        <h4>2.2.2 AWS EC2</h4>
                        The second service in the service flow is a load balancer. Besides being a hosting service, AWS EC2 also provides neat integrations with said hosts such as load balancing, scaling groups, AMI market etc. In order to offload requests of our microservices an Application Load Balancer is used.
                        A first version of the application also considers self managing and deploying the ElasticSearch storage to an EC2 instance.
                    </section>
                    <section>
                        <h4>2.2.3 Elastic Container Service</h4>
                        The mentioned load balancer front faces an ECS cluster. Amazon ECS is a fully managed container orchestration service with the purpose of easing deployment, service and resources management and scaling. What makes deployments easier is the fact that the ECS cluster is a hybrid enironment in regards to the runtimes and types of applications deployed. Elastic container registry is a service like feature integrated with ECS with the purpose of centralizing docker images used in deployment. We use ECS to deploy the frontend service, the authentication service and the query backend service in sepparate containers. ECS allows us to customize the host resources of each service, which helps with optimizing resource allocation. This also means that each type of service is scaled individually with respect to each container traffic load and each custom setting configured prior to deployment.
                        In addition to the scaling feature, Amazon also provides it's own on demand serverless containers to use with ECS. ECS with Fargate is the managed AWS alternative to using Kubernetes. The main advantage for us in using Fargate is that there are no upfront expenses since it follows the pay for only what you use paradigm.
                    </section>
                    <section>
                        <h4>2.2.4 Amazon Relational Database Service</h4>
                        Amazon RDS, specifically their in house built engine Aurora is a high performance serverless SQL database. The main role of the database is to store user data, including hashed credentials and profile data. The advantages of using Amazon RDS include high performance and scalability while still paying for only what you are using, fully delegation of management and integrations with AWS ecosystem from which main benefits is the ease of securing the database through VPCs and encrpytion services such as AWS KMS.
                    </section>
                    <section>
                        <h4>2.2.5 Authentication</h4>
                        Authenticating the user is a very important step of the work-flow of the appliction. While not required, authenticating enables filtering and context based suggestions to a registered user.
                        The authentication flow starts at the signup/login web page. After the user enters his existing email address and password, or registers for a new account, the app sends his credentials through API Gateway to a spring microservice that hashes the password and stores the user's email address and password, along with all the other required fields, inside RDS, returning a JWT token for further authentication of requests later on.
                        If the user is already registered, sending his login information only verifies it to the existing information based on the email addres the user has provided. If it the hashed password matches the existing one for that email address, the rest is the same as for registering, where the app returns a JWT token for further authentication. In case the password is not a match, the user is prompted with an error, with the ability of trying again.
                    </section>
                </section>
            </section>
            <section>
                <h2>3.0 Infrastructure cost</h2>
                Although we can't estimate the monthly cost of the infrastructure, we can outline the cost of each provided service as of the time of publishing this report.
                <p>
                    API Gateway charges 0.9 USD per a million requests. Keep in mind that each use case encapsulates several requests due to the service oriented architecture. On average each client request will retrieve static assets from the frontend service, the frontend service will forward the request to the backend through the same domain, hitting API Gateway resulting in 2 requests.
                </p>
                <p>
                    The load balancer has a fixed cost of 0.0225 USD per hour since it will always be up and running. As for the EC2 instance hosting the ElasticSearch storage, ideally a m5.2xlarge type instance would be used. For an hourly 0.384 USD the ElasticSearch would benefit from a 8 vCPU, 32 Gb of RAM and high performance network traffic.
                </p>
                <p>
                    ECS Fargate containers price is calculated per second with a 1 minute minimum. For Linux instances the hourly prices per vCPU and GB of RAM are 0.04048 USD, respectively 0.004445 USD. Depending on the necessities of the service multiple incremental configurations are available ranging from 0.25 vCPU and 0.5 GB to 2 GB of ram to 4 vCPU and 8 GB to 30 GB.
                </p>
                <p>
                    Lastly Amazon Aurora charges 0.1 USD per GB of monthly storage along with 0.2 USD per 1 million requests consisting of I/O operations.
                </p>
            </section>
            <section>
                <h2>4.0 Implementation</h2>
                <section>
                    <h3>4.1 RDF Store</h3>
                    <section>
                        <h4>4.1.1 Initial plan divergence and caveats</h4>
                        <p> One of the most important factors in choosing to use Eclipse RDF4J was its integration features
                        with several components we considered using in order to build a solid application, those being
                        ElasticSearch noSql for database, Spring Boot for microservices and transactional APIs. More
                        specifically we planned to use the RDF4J repository API for ElasticSearch stores which
                        trivially integrates with a running ES host, only requiring the host's address, cluster name and
                        index to be used. The repository's connection could then be used to execute SparQL queries,
                        file loading, or simple triples operations such as searching, adding or removing. The Spring
                        integration adds a DAO layer with an implemented CRUD interface which should be agnostic
                        in terms of the repository implementation used. After several attempts of integrating, we
                        got an answer from the developers, suggesting this specific integration between ES repository
                            and Spring DAO interfaces was not yet attempted. </p>
                        <p> We decided to follow the developers advice and use in-memory storage. Taking this a step
                        further, to encourage forward compatibility, once the ES repo - Spring DAO integration is tested
                        , with different storage systems, we opted to use a remote host and repository for the in-memory
                         storage using the RDF4J server feature</p>
                        <p> This solution raises drawbacks in terms of horizontal scalability, data replication
                            and the option of delegating host maintenance to a 3rd party such as a cloud service
                            provider to ensure high availability and durability. In terms of the desired features
                            from an RDF store, this solution is viable as it still very fast in terms of read/write
                         operations, and it can be extended with full text search capabilities. </p>
                    </section>
                    <section>
                        <h4 id="rdf4jServer">4.1.2 RD4J Server</h4>
                        <p> The RDF4J server is a SPARQL endpoint accessible via HTTP. Since at it's core it's a web
                            application resource deployed in an Apache Tomcat container it can be used as a standalone
                        RDF store, leveraging the container's thread pool configuration which encourage vertical
                            scaling</p>
                        <p> In order to deploy and configure the RDF store, the rdf4j-server.war WAR must be deployed
                        in a Tomcat container and configured with the appropriate repository configuration. We opted to
                            use the RDF4J Sail API and use a SailRepository which enables us to stack multiple
                            repository implementations on top of each other. This allows us to use a LuceneRepository
                        on top of a NativeRepository. We explain the implications of the mentioned APIs in the
                        following sections.</p>
                        <p> Once deployed we can access the RDF store via the configured repository using the
                        RDF store hots's address and the repository's Id </p>
                    </section>
                    <section>
                        <h4>4.1.3 Repository API</h4>
                        <p> We mentioned the term repository, and we are going to keep referencing it. This section
                        describes the concept along with more technical aspects regarding the RDF4J library.</p>
                        <p> Quoting from Eric Evan's book Domain-Driven Design, the “repository is a mechanism for
                        encapsulating storage, retrieval, and search behavior, which emulates a collection of objects.”
                            The RDF4J repository implementation is mainly used to fetch a connection to the store,
                            used to commit CRUD operations. The Spring integration provides a wrapper with basic
                            CRUD operations implemented, vended thorough a simple interface. This strongly ties in with
                            Java's strong oop patterns, requiring the following: an entity class upon which operations
                             are executed, a field specification representing the entity's id property, multiple field
                            specification representing properties that can take part in update operations, a simple
                            SPARQL query for reading and one for inserting one entity, and a map method implemented
                            to describe how to map the fetched triples back to an entity object. In our implementation
                            we use 3 DAO classes that satisfy the mentioned requirements for handling the following
                            entities: Beverage, BeverageContext and Profile.
                        </p>
                        <p id="tripleMention"> An important mention is that the data representation in the RDF store consists of triples,
                         even though in the business layer we use OOP models. This can be best exemplified through the
                        fact that we populate the RDF store from a data.ttl file consisting of multiple beverages,
                        profiles and beverage contexts described as triples. After loading the triples through the
                        connection API, we can use the repository API to access the triples and model them into
                        OOP entities.</p>

                    </section>
                    <section>
                        <h4>4.1.4 Native storage</h4>
                        <p> The Native repository API enables data storing on disk. The documentation reports that
                        the main memory store is by far the fastest repository that can be used and the Native
                            implementation acts just like one since, within the limits of physical
                            memory, the read/write operations will be cached by the OS. The documentation also
                        states that the Native store is suitable for up 100 million triples.</p>
                    </section>
                    <section>
                        <h4>4.1.5 Lucene index</h4>
                        <p> Apache Lucene is a project consisting of multiple libraries that offer support for text indexing
                        with the purpose of enabling complex features such as full text searching, spellchecking,
                            hit highlighting, tokenization. </p>
                        <p> RDF4J vends a repository implementation for working with Lucene indexes. Moreover, besides
                         support for Lucene integration with hosts such as ElasticSearch or Solr, an implementation for
                        in memory indexes is available and can be integrated with the mentioned Native storage and
                        repository. We mainly use the Lucene index for searching terms over the beverage's description,
                        but the features of the application can be further extended. </p>
                    </section>
                </section>
                <section>
                    <h3>4.2 Application </h3>
                    <p> A 3 tier architecture is used to build the application. As mentioned in the
                        <a href="#designAndArchitecture">design and architecture section</a>, an Angular application is
                        used in the presentation layer in order to render on client side data fetched from the APIs
                        exposed by the Spring services in the application layer. As mentioned in the
                        <a href="#rdf4jServer">RDF store</a> segment, in the end, we opted to use an RDF4J server for
                        our Data layer.
                    </p>
                    <section>
                        <h4>4.3.1 Backend design </h4>
                        <section>
                            <h5>4.3.1.1 Model UML</h5>
                            <figure id="fig1">
                                <img src="https://raw.githubusercontent.com/AdrianHamod/BeverageManager/main/architecture/uml/model_uml.jpg">
                                <figcaption>fig. 1</figcaption>
                            </figure>
                            <p>&nbsp;</p>
                        </section>
                        <section>
                        <h5>4.3.1.2 Controller-Transactional-DAO UML</h5>
                        <figure id="fig2" typeof="sa:image">
                            <img src="https://raw.githubusercontent.com/AdrianHamod/BeverageManager/main/architecture/uml/query_backend_umlv4.jpg">
                            <figcaption>fig. 2</figcaption>
                        </figure>
                        <p>&nbsp;</p>
                        <p>&nbsp;</p>
                        </section>
                        <section>
                            <h5>4.3.1.3 DAO Layer</h5>
                            <p>As we mentioned in the <a href="#tripleMention">repository</a> section, the RDF store will
                            store our data in triples format. Using the low level connection API enables us to work
                            directly with the triples. The DAO classes enable us to abstract the triple processing through
                            mapping them to real entities such as the classes described in the <a href="#fig1">model diagram</a>.
                            Along with implementing the mapping, there are several steps required in order to abstract
                            CRUD operations. We will go through the BeverageDao class to showcase a real example and explore
                            current shortcomings.</p>
                            <ol>
                                <li>Class declaration</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Component
public class BeverageDao extends SimpleRDF4JCRUDDao&lt;Beverage, IRI>
                                        </code>
                                    </pre>
                                </figure>
                                The org.eclipse.rdf4j.spring.dao.SimpleRDF4JCRUDDao abstract class has to be extended
                                with the appropriate generics. In this example, the ENTITY generic is set to Beverage
                                class and the ID type of the Beverage is set to IRI. The BeverageDao constructor also
                                has to match the base class constructor; annotating the class with @Component ensures
                                the object will be managed by the Spring container and injected with the beans passed
                                in the constructor, specifically the RDF4JTemplate. The RDF4JTemplate object is used
                                internally to fetch the connection instance and implement the CRUD.
                                <li>Input id generation</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected IRI getInputId(Beverage beverage) {
    return beverage.getBeverageId();
}
                                        </code>
                                    </pre>
                                </figure>
                                We can implement ourselves the id generation logic. This could be used to generate an id
                                if the passed entity is missing the id value. We simply return the mandatory id configured
                                at model level.
                                <li>Setting bindings</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected void populateIdBindings(MutableBindings mutableBindings, IRI iri) {
    mutableBindings.add(BEVERAGE_ID, iri);
}

@Override
protected void populateBindingsForUpdate(MutableBindings bindingsBuilder, Beverage beverage) {
    bindingsBuilder
            .add(NAME, beverage.getName())
            .add(PARENT, beverage.getParent())
            .add(DESCRIPTION, beverage.getDescription())
            .add(IMAGE_URL, beverage.getImageUrl());

    bindingsBuilder.add(ALLERGENS, String.join(", ", beverage.getAllergens()));
}
                                        </code>
                                    </pre>
                                </figure>
                                <p> The bindings are used by queries to populate the query parameters with the specified
                                values. In order to implement *byId operations, there is a clear distinction between
                                    the id field and the rest of mutable fields. </p>
                                <p> Notice the allergens list attribute cast to String using the join operation. As of
                                    now collection serialization is not supported, and we need to handle it ourselves.
                                Later, when we are mapping the fetched the triples to entities,
                                    we perform a similar operation in order to cast back to a List object. Although the
                                Spring integration does not currently support collection bindings, it's important to
                                    mention that the RDF4J API support collection operations through their Model API.</p>
                                <li>Reading one entity</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected String getReadQuery() {
    SelectQuery selectQuery = Queries.SELECT();
    String readQuery = selectQuery.select(BEVERAGE_ID, NAME, PARENT, DESCRIPTION, NAME, IMAGE_URL, ALLERGENS)
            .where(
                    BEVERAGE_ID.isA(OWL.CLASS)
                            .andHas(RDFS.SUBCLASSOF, PARENT)
                            .andHas(DC.DESCRIPTION, DESCRIPTION)
                            .and(BEVERAGE_ID.has(FOAF.NAME, NAME).optional())
                            .and(BEVERAGE_ID.has(ObjectType.IMAGE, IMAGE_URL).optional())
                            .and(BEVERAGE_ID.has(ObjectType.ALLERGENS, ALLERGENS).optional())
            )
            .getQueryString();
    return readQuery;
}
                                        </code>
                                    </pre>
                                </figure>
                                The getReadQuery is used to read exactly 1 entity (or none if not found). This is the
                                building block method that is used in all read operations.
                                <li>Mapping triples to entities</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected Beverage mapSolution(BindingSet querySolution) {
    Beverage beverage = new Beverage();
    beverage.setBeverageId(iri(QueryResultUtils.getString(querySolution, BEVERAGE_ID)));
    beverage.setName(QueryResultUtils.getStringMaybe(querySolution, NAME));
    beverage.setParent(QueryResultUtils.getIRI(querySolution, PARENT));
    beverage.setDescription(QueryResultUtils.getString(querySolution, DESCRIPTION));
    beverage.setImageUrl(QueryResultUtils.getStringMaybe(querySolution, IMAGE_URL));
    beverage.setAllergens(
            List.of(QueryResultUtils.getStringOptional(querySolution, ALLERGENS)
                    .orElse("").split(", "))
    );
    return beverage;
}
                                        </code>
                                    </pre>
                                </figure>
                                <p> The mapping method needs to be implemented by the library user. When fetched, the
                                results consists in a collection of triples. These are accessed through the passed
                                BindingSet parameter using the same binding constants used in the implemented
                                    getReadQuery method. </p>
                                <li>Insert one entity</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected NamedSparqlSupplier getInsertSparql(Beverage beverage) {
    return NamedSparqlSupplier.of("insert", () -> Queries.INSERT(
                    (TriplePattern) BEVERAGE_ID.isA(OWL.CLASS)
                            .andHas(RDFS.SUBCLASSOF, PARENT)
                            .andHas(DC.DESCRIPTION, DESCRIPTION)
                            .andHas(DC.FOAF.NAME, NAME)
                            .andHas(DC.ObjectType.IMAGE, IMAGE_URL)
                            .andHas(ObjectType.ALLERGENS, ALLERGENS)
            )
            .getQueryString());
}
                                        </code>
                                    </pre>
                                </figure>
                                Similarly the insert method needs to be implemented in order to use save/update
                                operations.
                                <li>Custom queries handled by DAO class</li>
                                <figure typeof="schema:SoftwareSourceCode">
                                    <pre>
                                        <code class="language-java">
@Override
protected NamedSparqlSupplierPreparer prepareNamedSparqlSuppliers(NamedSparqlSupplierPreparer preparer) {
    String descriptionFullTextSearch = "PREFIX search: &lt;http://www.openrdf.org/contrib/lucenesail#> " +
            "SELECT ?beverage_id ?beverage_description " +
            "WHERE { ?beverage_id search:matches [" +
            " search:query ?term ; " +
            " search:snippet ?beverage_description ] } ";

    String listAllChildren = "PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#> " +
            "PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#> " +
            "PREFIX owl: &lt;http://www.w3.org/2002/07/owl#> " +
            "SELECT ?beverage_id " +
            "WHERE { ?beverage_id rdfs:subClassOf ?beverage_parent . } ";

    return preparer.forKey(QUERY_KEYS.DESCRIPTION_FULL_TEXT_SEARCH)
            .supplySparql(descriptionFullTextSearch)
            .forKey(QUERY_KEYS.LIST_CHILDREN)
            .supplySparql(listAllChildren);
}
                                        </code>
                                    </pre>
                                </figure>
                                Finally, we can define custom queries TupleQueryEvaluationBuilder API; we provide a
                                SPARQL query string, bind values to parameters as we need and finally evaluate and
                                convert the execution to a list of bindings that we can map or fetch using the getById
                                method. What is really neat is that we can wrap the customer queries as well in
                                transactional operations inside the service classes.
                            </ol>
                        </section>
                        <section>
                            <h5>4.3.1.4 Controller and Transactional layers</h5>
                            The transactional layer is mainly a thin layer over DAO, annotated with @Transactional in
                            order to let the Spring container know that the TransactionManager should manage this
                            operations given appropriate roll back methods are implemented. The controller layer is a
                            think layer on top of the service layer that handles user input and allows the input to be
                            simplified, by handling the request parameters to entities mapping. (the user does not need
                            fill in IDs, or to build IRIs).
                        </section>
                        <section>
                            <h5>4.3.1.5 Queries</h5>
                            The queries we implement are the insert and select queries in the DAO layer. The mentioned
                            overridden getReadQuery and getInsertSparql methods alongside our custom queries for
                            retrieving beverages by a specified parent beverage and for indexed full text searches by
                            a specified term upon the beverage description.
                        </section>
                    </section>
                    <section>
                        <h4>4.3.2 Frontend design </h4>
                    </section>
                </section>
                <section>
                    <h3>4.3 Ontology</h3>
                    <p> In order to design the ontology we started with the project requirements, defined the frontend-backend
                    contracted and the OOP models we will use. Going further we reverse mapped the entities to triples,
                        considering the RDF4J workflow and chose a unclaimed domain for the namespace we were going to us.
                    </p>
                    <section>
                        <h4>4.3.1 Reused ontologies</h4>
                        <ul>
                        We reused classes and properties from the following namespaces:
                            <li>http://www.w3.org/2002/07/owl</li>
                            <li>http://www.w3.org/1999/02/22-rdf-syntax-ns</li>
                            <li>http://www.w3.org/2000/01/rdf-schema</li>
                            <li>http://xmlns.com/foaf/0.1/</li>
                            <li>http://purl.org/dc/elements/1.1/</li>
                            <li>http://www.schema.org/</li>
                        </ul>

                        <p> The root of our hierarchical structure is the `owl:Class` class. Each of the defined classes
                        are of type owl:Class.</p>
                        <p> The type of class is described through the rdf:type predicate.</p>
                        <p> All beverages, except the root beverage, are subclasses of another beverage. We use the
                            rdfs:subClassOf to describe it.</p>
                        <p> We use foaf:name to describe the name of a profile, of a beverage; we use foaf:gender to
                            describe the profile gender; foaf:knows is used to describe the relation between a profile
                        subject and a list of beverage preferences.</p>
                        <p> The dc:description predicate is used to describe a beverage subject's description literal</p>
                        <p> The http://www.schema.org/image of a beverage is used to describe the image url of a beverage</p>
                    </section>
                    <section>
                        <h4>4.3.2 Ontology classes and properties</h4>
                    </section>
                    <p> The root class for beverages is the :Beverage class. (prefixed by the unclaimed domain used as
                        namespace). Each beverage entry is either a subclass of :Beverage or another beverage subject.
                    </p>
                    <p> The properties we have to fill in ourselves are the following: `:allergens`, `:event`,
                        `:season`, `:preference`.</p>
                </section>
                <section>
                    <h3>4.4 Project requirements assessment</h3>
                    <p>Completed requirements</p>
                    <ol>
                        <li>Propose an ontological model regarding most common non-alcoholic beverages</li>
                        The models we use describe the ontological model. The use ontology model is used in the
                        data.ttl file we that use to load the RDF store.
                        <li>Create the knowledge graph including the user's preferences about beverages</li>
                        The initial knowledge graph is described in data.ttl file. Additional create operations update
                         the RDF store with triples, enhancing the knowledge graph.
                        <li>The beverage usage based on context</li>
                        Each profile can create e personal context regarding one beverage, stating the profile
                        preference on the beverage in question and additional data such as an event, a season or a
                        location that fits the context. This context can be created, updated and deleted. If a profile
                        accesses a beverage page, the beverage context will also be loaded if it exist.
                        <li>Useful beverage metadata</li>
                        We include a name, parent, description and an image in the Beverage model.
                        <li>Developed web application</li>
                        The application consists in a presentation layer, the Angular frontend, an application layer,
                        the Spring backend, and a data layer, the RDF4J server rdf store.
                        <li>Smart browsing and filtering</li>
                        For smart browsing we included a search based on terms that tries to match descriptions of
                        beverages. This search is based on the lucene index and lucene API. The executed query is
                        SPARQL. Trivial searches and filters include search by name and filter by parent name.
                        <li>Suggestions based on correlations</li>
                        We use a suggestion api to fetch beverages for the recommendation page and the beverage search.
                        This api is based on user preferences and correlations between beverages. More specifically
                        we perform a round-robin like BFS search starting from the positive preferences of a user (likes)
                        and searching around the liked beverage's knowledge graph, transversing based on a node's
                        parent and/or children.
                    </ol>
                </section>
            </section>
        </div>
    </header>
</article>
</html>
